{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2f5348-9cfc-4a5e-ab40-8d449e53ac74",
   "metadata": {},
   "source": [
    "## To Do List\n",
    "- Fix non running horses (should be fixed)\n",
    "- Fully automate\n",
    "- Fix non uploaded data issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2282f4-b9f7-4d19-b0d6-9929476b19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import re\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a2a423-bcd0-410b-bfa8-6e64c3ff1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    'Accept' : 'application/json',\n",
    "    'Content-Type' : 'application/json',\n",
    "    'Referer' : 'https://www.racingtv.com/',\n",
    "    'sec-ch-ua' : '\"Not;A=Brand\";v=\"99\", \"Google Chrome\";v=\"139\", \"Chromium\";v=\"139\"',\n",
    "    'sec-ch-ua-mobile' : '?0',\n",
    "    'sec-ch-ua-platform' : '\"Windows\"',\n",
    "    'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',\n",
    "    'x-requested-with' : 'racingtv-web/5.3.0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72288686-b990-49b4-aea8-338bb6bfb970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking data from one keyword\n",
    "def one_filter(data, keyword):\n",
    "    try:\n",
    "        return data[keyword]\n",
    "    # Issues occur if return np.nan so return 'N/A'\n",
    "    except:\n",
    "        return 'N/A'\n",
    "\n",
    "# Picking data from three keywords\n",
    "def three_filter(data, keyword1, keyword2, keyword3):\n",
    "    try:\n",
    "        return data[keyword1][keyword2][keyword3]\n",
    "    # Issues occur if return np.nan so return 'N/A'\n",
    "    except:\n",
    "        return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de9c624-d07d-4e0d-87a6-994cc447cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_race_data(data_response, race_response):\n",
    "    \"\"\"\n",
    "    Collects and organises data from a horse race using API responses.\n",
    "\n",
    "    Keyword arguments:\n",
    "        data_response -- HTTP response containing horse metric data\n",
    "        race_response -- HTTP response containing race and runner data\n",
    "\n",
    "    Returns:\n",
    "        dict -- Structured horse racing data with metrics and race info\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks first API calls was successful and extracts the horses' metric data.\n",
    "    if data_response.status_code == 200:\n",
    "        try:\n",
    "            metric_data = data_response.json()['horses']\n",
    "        except:\n",
    "            print('Could not find \"horses\" in the json')\n",
    "            return 'No horse data'\n",
    "    else:\n",
    "        print('Response code: {:d}'.format(data_response.status_code))\n",
    "        print('Problem url is: {:s}'.format(data_response.url))\n",
    "        return\n",
    "\n",
    "    # Checks second API calls was successful and extracts the race and runner data.\n",
    "    if race_response.status_code == 200:\n",
    "        try:\n",
    "            race_data = race_response.json()['race']\n",
    "        except:\n",
    "            print('Could not find \"race\" in the json')\n",
    "            print('Problem url is: {:s}'.format(race_url))\n",
    "            print('Aborting data collection')\n",
    "            return\n",
    "    else:\n",
    "        print('Error code {:d}'.format(race_response.status_code))\n",
    "        print('Problem url is: {:s}'.format(race_response.url))\n",
    "        return\n",
    "\n",
    "    # Initialise empty lists to store relevant data for each horse.\n",
    "    horse, position, finish_speed_value, finish_speed_rank, finish_speed_avrg, finish_speed_prct, top_speed_value, top_speed_rank, top_speed_avrg, top_speed_prct, race_id, race_type, location, trainer, jockey, owner, age = ([] for i in range(17))\n",
    "\n",
    "    # Create a list of horses which finished the race.\n",
    "    finished_horses = []\n",
    "    for data in metric_data:\n",
    "        if data['finish_position'] != None:\n",
    "            finished_horses.append(data['horse_name'])\n",
    "\n",
    "    num_finished = len(finished_horses)\n",
    "\n",
    "    # Collect data for each horse that finished the race.\n",
    "    for i in range(num_finished):\n",
    "        # Horse name and finishing position\n",
    "        horse.append(one_filter(metric_data[i], 'horse_name'))\n",
    "        position.append(one_filter(metric_data[i], 'finish_position'))\n",
    "\n",
    "        # Finishing speed data\n",
    "        finish_speed_value.append(three_filter(metric_data[i], 'metrics', 'fsp', 'value'))\n",
    "        finish_speed_rank.append(three_filter(metric_data[i], 'metrics', 'fsp', 'rank'))\n",
    "        finish_speed_avrg.append(three_filter(metric_data[i], 'metrics', 'fsp', 'average'))\n",
    "        finish_speed_prct.append(three_filter(metric_data[i], 'metrics', 'fsp', 'percentage'))\n",
    "\n",
    "        # Top speed data\n",
    "        top_speed_value.append(three_filter(metric_data[i], 'metrics', 'top_speed', 'value'))\n",
    "        top_speed_rank.append(three_filter(metric_data[i], 'metrics', 'top_speed', 'rank'))\n",
    "        top_speed_avrg.append(three_filter(metric_data[i], 'metrics', 'top_speed', 'average'))\n",
    "        top_speed_prct.append(three_filter(metric_data[i], 'metrics', 'top_speed', 'percentage'))\n",
    "\n",
    "        # More information about the horse\n",
    "        trainer.append(one_filter(race_data['runners'][i], 'trainer_name'))\n",
    "        jockey.append(one_filter(race_data['runners'][i], 'jockey_name'))\n",
    "        owner.append(one_filter(race_data['runners'][i], 'owner_name'))\n",
    "        age.append(one_filter(race_data['runners'][i], 'age'))\n",
    "\n",
    "    # Consolidating all the horse data into a dict\n",
    "    horse_info = {\n",
    "        'Horse' : horse,\n",
    "        'Position' : position,\n",
    "        'Finishing Speed (%)' : finish_speed_value,\n",
    "        'Finishing Speed Rank' : finish_speed_rank,\n",
    "        'Finishing Speed Average' : finish_speed_avrg,\n",
    "        'Finishing Speed Percentage' : finish_speed_prct,\n",
    "        'Top Speed Value (mph)' : top_speed_value,\n",
    "        'Top Speed Rank' : top_speed_rank,\n",
    "        'Top Speed Average' : top_speed_avrg,\n",
    "        'Top Speed Percentage' : top_speed_prct,\n",
    "\n",
    "        # Track data is replicated for each horse\n",
    "        'Race Id' : [race_data['id']] * num_finished,\n",
    "        'Race Type' : [race_data['race_type']] * num_finished,\n",
    "        'Location' : [race_data['meeting']['track']['name']] * num_finished,\n",
    "        \n",
    "        'Trainer' : trainer,\n",
    "        'Jockey' : jockey,\n",
    "        'Owner' : owner,\n",
    "        'Age' : age,\n",
    "        }\n",
    "\n",
    "    return horse_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae59bd5d-64b2-4e4a-a238-48f58da6161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_times(date, delay = 1, DEBUG = False):\n",
    "    # Only looking at UK and Ireland tracks\n",
    "    with open('track_names.json', 'r') as fp:\n",
    "        approved_tracks = json.load(fp)['Track Names']\n",
    "    \n",
    "    time.sleep(delay)\n",
    "    response = requests.get('https://api.racingtv.com/racing/results/list/{:s}?'.format(date), headers = HEADERS)\n",
    "    time_dict = {}\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            race_meetings = response.json()['meetings']\n",
    "        except:\n",
    "            print('Could not find \"meetings\" in the json')\n",
    "            print('Problem url is: https://api.racingtv.com/racing/results/list/{:s}?'.format(date))\n",
    "            print('Aborting data collection')\n",
    "            return\n",
    "    for data1 in race_meetings:\n",
    "        track_name = data1['track']['name']\n",
    "        if track_name in approved_tracks:\n",
    "            time_data = []\n",
    "            for data2 in data1['completed_races']:\n",
    "                timestamp = pd.to_datetime(data2['start_time_scheduled'])\n",
    "                time_data.append(str(timestamp.time())[0:5].replace(':', ''))\n",
    "            time_dict[track_name] = time_data\n",
    "        elif DEBUG:\n",
    "            # Write to text file\n",
    "            with open('race_times_debug.txt', 'a') as fp:\n",
    "                fp.write('{:s} is not an approved track\\n'.format(track_name))\n",
    "\n",
    "    return time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a39641f-0db6-48d5-89a9-226140478c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_race_times(start_date, end_date, delay = 1, write_out = False, \n",
    "                           file_name = 'race_times{:s}'.format(str(pd.Timestamp.today().date())), \n",
    "                           DEBUG = False):\n",
    "    date_range = pd.date_range(start = start_date, end = end_date, freq = 'D')\n",
    "    time_data = {}\n",
    "    for date in date_range:\n",
    "        date_str = str(date.date())\n",
    "        time_data.update({date_str : race_times(date_str, delay, DEBUG)})\n",
    "        if DEBUG:\n",
    "            with open('race_times_debug.txt', 'a') as fp:\n",
    "                fp.write('Collected race times for {:s}'.format(date_str))\n",
    "\n",
    "    if write_out:\n",
    "        with open(file_name, 'w') as fp:\n",
    "            json.dump(time_data, fp)\n",
    "        \n",
    "    return time_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7e36bc7-f216-4f11-a64c-6d52abcb4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_day_data(date, times, trackname, delay = 1, DEBUG = False):\n",
    "    # Changing name of edge cases\n",
    "    if trackname.lower() == 'lingfield':\n",
    "        trackname = trackname + '-Park'\n",
    "    # Replace space with - to make urls work\n",
    "    trackname = trackname.replace(' ', '-')\n",
    "\n",
    "    print(trackname)\n",
    "    \n",
    "    data = {}\n",
    "    for race_time in times:\n",
    "        data_url = 'https://api.racingtv.com/racing/iq-results/{:s}/{:s}/{:s}/comparison?'.format(date, trackname.lower(), race_time)\n",
    "        race_url = 'https://api.racingtv.com/racing/results/{:s}/{:s}/{:s}?'.format(date, trackname.lower(), race_time)\n",
    "        time.sleep(delay)\n",
    "        race_response = requests.get(race_url, headers = HEADERS)\n",
    "        if race_response.json()['race']['status']['state'] != 'abandoned':\n",
    "            time.sleep(delay)\n",
    "            data_response = requests.get(data_url, headers = HEADERS)\n",
    "            collected_race_data = collect_race_data(data_response, race_response)\n",
    "            # If there is horse data, update data\n",
    "            if collected_race_data != 'No horse data':\n",
    "                data.update({race_time[:2] + ':' + race_time[2:] : collected_race_data})\n",
    "            elif DEBUG:\n",
    "                print('{:s}/{:s}/{:s} has no horse data'.format(date, trackname.lower(), race_time))\n",
    "        elif DEBUG:\n",
    "            print('{:s}/{:s}/{:s} was abandoned'.format(date, trackname.lower(), race_time))\n",
    "\n",
    "        print('Collected race data for {:s} at {:s}'.format(trackname, race_time[:2] + ':' + race_time[2:]))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be992b5-3397-482c-beaf-ab0f2055393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_day_data(day_races, date, delay = 1, DEBUG = False):\n",
    "    # For checking progress\n",
    "    progress = 0\n",
    "    count = len(day_races.values())\n",
    "        \n",
    "    data = {}\n",
    "    for trackname, times in day_races.items():\n",
    "        progress += 1\n",
    "        track_dict = track_day_data(date, times, trackname, delay, DEBUG)\n",
    "        # If track_dict is not empty, update data\n",
    "        if track_dict:\n",
    "            data.update({trackname : track_dict})\n",
    "        print('Progress: {:d}/{:d}'.format(progress, count))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee1e8127-8f55-46fa-b941-da833561437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_names(delay = 1, write_out = False):\n",
    "    uk_url = 'https://api.racingtv.com//racing/tracks/uk?'\n",
    "    uk_response = requests.get(uk_url, headers = HEADERS)\n",
    "    if uk_response.status_code != 200:\n",
    "        print('Problem with the url: {:s}'.format(uk_url))\n",
    "        return\n",
    "    \n",
    "    time.sleep(delay)\n",
    "    \n",
    "    ire_url = 'https://api.racingtv.com//racing/tracks/ire?'\n",
    "    ire_response = requests.get(ire_url, headers = HEADERS)\n",
    "    if ire_response.status_code != 200:\n",
    "        print('Problem with the url: {:s}'.format(ire_url))\n",
    "        return\n",
    "\n",
    "    track_list = []\n",
    "\n",
    "    for data in uk_response.json()['tracks']:\n",
    "        track_list.append(data['name'])\n",
    "    for data in ire_response.json()['tracks']:\n",
    "        track_list.append(data['name'])\n",
    "\n",
    "    #Writing track names to a json file\n",
    "    if write_out == True:\n",
    "        with open('track_names.json', 'w') as fp:\n",
    "            json.dump({'Track Names' : track_list}, fp)\n",
    "        \n",
    "    return track_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ff5a04-3118-43b6-bd49-79847bbc881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collection_of_race_data(start_date, end_date, delay = 1,\n",
    "                            write_out = True,\n",
    "                            return_data = True,\n",
    "                            DEBUG = False):\n",
    "    \n",
    "    try:\n",
    "        with open('race_times.json', 'r') as fp:\n",
    "            all_race_times = json.load(fp)\n",
    "    except:\n",
    "        print('Collecting track times')\n",
    "        all_race_times = collect_all_race_times(start_date, end_date, delay, write_out,\n",
    "                                                file_name = 'race_times'.format(start_date, end_date),\n",
    "                                                DEBUG = False)\n",
    "\n",
    "    data_dict = {}\n",
    "    date_range = pd.date_range(start_date, end_date, freq = 'D')\n",
    "\n",
    "    for date in date_range:\n",
    "        date_str = str(date.date())\n",
    "        print('Collecting data for {:s}'.format(date_str))\n",
    "        all_day_data = collect_all_day_data(all_race_times[date_str], date_str, delay, DEBUG = False)\n",
    "        # If all_day_data is not empty, update data_dict\n",
    "        if all_day_data:\n",
    "            data_dict.update({date_str : all_day_data})\n",
    "\n",
    "    # Below conditions need some fixing\n",
    "    \n",
    "    if write_out:\n",
    "        with open('historical_horse_data_{:s}_{:s}.json'.format(start_date, end_date), 'w') as fp:\n",
    "            json.dump(data_dict, fp)\n",
    "\n",
    "    # Below does match write_out bool\n",
    "    \n",
    "    if return_data:\n",
    "        print('Data saved to: historical_horse_data.json')\n",
    "        return data_dict\n",
    "    else:\n",
    "        return 'Data saved to: historical_horse_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccafe642-9047-40a8-bed5-9711a0efb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_json_to_df(json_file):\n",
    "    with open(json_file, 'r') as fp:\n",
    "        race_data = json.load(fp)\n",
    "\n",
    "    simple_list = []\n",
    "    for date in race_data.keys():\n",
    "        for track in race_data[date].keys():\n",
    "            for time in race_data[date][track].keys():\n",
    "                for i in range(len(race_data[date][track][time]['Horse'])):\n",
    "                    useful_data = race_data[date][track][time]\n",
    "\n",
    "\n",
    "                    #temporary fix\n",
    "                    if date == '2025-05-24' and track == 'Windsor' and useful_data['Horse'][i] == 'Dubai Time':\n",
    "                        continue\n",
    "                    if date == '2025-08-04' and track == 'Windsor' and useful_data['Horse'][i] == 'Piscean Star':\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        # print('{:s}{:s}{:s}'.format(date, track, time))\n",
    "                        simple_list.append({\n",
    "                            'Date' : date,\n",
    "                            'Track' : track,\n",
    "                            'Time' : time,\n",
    "                            'Horse' : useful_data['Horse'][i],\n",
    "                            'Position' : useful_data['Position'][i],\n",
    "                            'Finishing Speed (%)' : useful_data['Finishing Speed (%)'][i],\n",
    "                            'Top Speed Value (mph)' : useful_data['Top Speed Value (mph)'][i],\n",
    "                            'Race Id' : useful_data['Race Id'][i],\n",
    "                            'Race Type' : useful_data['Race Type'][i],\n",
    "                            'Trainer' : useful_data['Trainer'][i],\n",
    "                            'Jockey' : useful_data['Jockey'][i],\n",
    "                            'Owner' : useful_data['Owner'][i],\n",
    "                            'Age' : useful_data['Age'][i],\n",
    "                        })\n",
    "\n",
    "    return pd.json_normalize(simple_list).set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1afae47c-c04b-4096-9d37-849f95915289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_condition(df, race_id):\n",
    "    # Select horse in a race which have a finishing speed above the median\n",
    "    filtered_speed = df[(df['Race Id'] == race_id) & (df['Finishing Speed (%)'] >= df[df['Race Id'] == race_id][['Finishing Speed (%)']].quantile(q = 0.5).iloc[0])]['Finishing Speed (%)']\n",
    "\n",
    "    # Find the mean and standard deviation of these finishing speeds\n",
    "    mean = filtered_speed.mean()\n",
    "    std = filtered_speed.std()\n",
    "\n",
    "    return [mean, std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6528f41-f090-4ed0-a1dd-d2892a86bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_race_data(delay = 1):\n",
    "    # Loading in historical data\n",
    "    with open('historical_horse_data.json', 'r') as fp:\n",
    "        historical_data = json.load(fp)\n",
    "    # Loading in historical race times\n",
    "    with open('race_times.json', 'r') as fp:\n",
    "        historical_race_times = json.load(fp)\n",
    "    \n",
    "    # Last date in historical data\n",
    "    last_date = pd.Timestamp(list(historical_data.keys())[-1])\n",
    "    # Start one day after last date\n",
    "    start_date = last_date + pd.Timedelta(days = 1)\n",
    "    start_date_str = str(start_date.date())\n",
    "    # End two days before current date (data from yesterday isn't always available on the website)\n",
    "    end_date = pd.Timestamp.today() - pd.Timedelta(days = 2)\n",
    "    end_date_str = str(end_date.date())\n",
    "\n",
    "    if start_date <= end_date:\n",
    "        # Collecting race times between start_date and end_date\n",
    "        new_race_times = collect_all_race_times(start_date, end_date, delay, write_out = False)\n",
    "        \n",
    "        # Update race times data and json file\n",
    "        historical_race_times.update(new_race_times)\n",
    "        with open('race_times.json', 'w') as fp:\n",
    "            json.dump(historical_race_times, fp)\n",
    "\n",
    "        # Collecting race data between start_date and end_date\n",
    "        new_data = collection_of_race_data(start_date, end_date, delay, write_out = False)\n",
    "        \n",
    "        # Update race data and json file\n",
    "        historical_data.update(new_data)\n",
    "        with open('historical_horse_data.json', 'w') as fp:\n",
    "            json.dump(historical_data, fp)\n",
    "    else:\n",
    "        return 'Date is already up to date.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2b329f5-7d35-441f-98c7-0fbaabcc9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_todays_urls():\n",
    "    \"\"\"\n",
    "    Collects the urls of todays races in UK and Ireland on racingpost\n",
    "\n",
    "    Returns:\n",
    "        list -- A list containing three elements:\n",
    "              - race_tracks (list): Names of the race tracks\n",
    "              - times (list): Race times\n",
    "              - links (list): Race urls on racingpost\n",
    "    \"\"\"\n",
    "\n",
    "    url = 'https://www.racingpost.com/racecards/'\n",
    "    response = requests.get(url, headers = HEADERS)\n",
    "\n",
    "    # Checks if the request was successful.\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        except:\n",
    "            print('Failed to collect todays racingpost html.')\n",
    "            return\n",
    "    else:\n",
    "        print('Response code {:d}'.format(response.status_code))\n",
    "        return\n",
    "\n",
    "    # Importing the names of the UK are Ireland race tracks\n",
    "    with open('track_names.json', 'r') as fp:\n",
    "        track_names = json.load(fp)['Track Names']\n",
    "\n",
    "    links = []\n",
    "    race_tracks = []\n",
    "    times = []\n",
    "    seen_ids = []\n",
    "\n",
    "    # Filtering the html to where todays race urls are located\n",
    "    for a in soup.find_all('a', {'class' : 'RC-meetingItem__link', 'href' : True}):\n",
    "        race_id = a['data-race-id']\n",
    "        # Check if we have already seen race id to prevent duplicates.\n",
    "        if race_id not in seen_ids:\n",
    "            seen_ids.append(race_id)\n",
    "            # Only want race tracks in the UK and Ireland.\n",
    "            # Some racecourses end in ' (AW)', which we want to remove.\n",
    "            racecourse = a['data-racecourse'].removesuffix(' (AW)')\n",
    "            if racecourse in track_names:\n",
    "                links.append('https://www.racingpost.com' + a['href'])\n",
    "                race_tracks.append(racecourse)\n",
    "                \n",
    "                time = a['data-race-date']\n",
    "                times.append(pd.Timestamp(time).strftime('%H:%M'))\n",
    "\n",
    "    return [race_tracks, times, links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d4f3e6-aac3-469a-8582-14023ea205a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_html(wrapper, tag1, tag2, element):\n",
    "    try:\n",
    "        return wrapper.find(tag1, {tag2 : element}).get_text().strip()\n",
    "    except:\n",
    "        return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c00716e-72cd-4279-aaf5-659d0c138bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_race_today(url, delay = 1):\n",
    "    \"\"\"\n",
    "    Collects and organises data from the urls html.\n",
    "\n",
    "    Keyword arguments:\n",
    "        url -- Racingpost url of the desired horse race\n",
    "        delay -- Delay between making requests to the server (only needed if looping over this function)\n",
    "\n",
    "    Returns:\n",
    "        dict -- Structured horse racing data with useful information about each horse\n",
    "    \"\"\"\n",
    "    \n",
    "    time.sleep(delay)\n",
    "    response = requests.get(url, headers = HEADERS)\n",
    "\n",
    "    # Checks if request was successful\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        except:\n",
    "            print('Failed to collect html from {:s}'.format(url))\n",
    "            return\n",
    "    else:\n",
    "        print('Response code: {:d}'.format(data_response.status_code))\n",
    "        print('Problem url is: {:s}'.format(url))\n",
    "        return\n",
    "\n",
    "    # Filtering html to where the horse info is located.\n",
    "    filtered = soup.find_all('div', {'class' : 'RC-runnerCardWrapper'})\n",
    "\n",
    "    # Initialise empty lists to store relevant horse data.\n",
    "    horses, runner_nums, tips, last_ran, ages, prize = ([] for i in range(6))\n",
    "    \n",
    "    for wrapper in filtered:\n",
    "        # Want to exclude non running horse.\n",
    "        try:\n",
    "            runner_number = int(wrapper.find('span', {'data-test-selector' : 'RC-cardPage-runnerNumber-no'}).get_text().strip())\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Collecting horse data and storing in lists.\n",
    "        horses.append(filter_html(wrapper, 'a', 'data-test-selector', 'RC-cardPage-runnerName'))\n",
    "        runner_nums.append(filter_html(wrapper, 'span', 'data-test-selector', 'RC-cardPage-runnerNumber-no'))\n",
    "        tips.append(filter_html(wrapper, 'div', 'class', 'RC-runnerStats__tips'))\n",
    "        last_ran.append(filter_html(wrapper, 'div', 'data-test-selector', 'RC-cardPage-runnerStats-lastRun'))\n",
    "        ages.append(filter_html(wrapper, 'span', 'data-test-selector', 'RC-cardPage-runnerAge'))\n",
    "\n",
    "    # Consolidating all the horse data into a dict.\n",
    "    race_info = {\n",
    "        'Horse' : horses,\n",
    "        'Runner Num' : runner_nums,\n",
    "        'Tips' : tips,\n",
    "        'Last Ran' : last_ran,\n",
    "        'Ages' : ages\n",
    "    }\n",
    "\n",
    "    return race_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56213e1c-4f19-41d5-9ee5-b9519b2147d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_races_today(delay = 1):\n",
    "    collection = collect_todays_urls()\n",
    "    race_tracks, times, urls = (collection[i] for i in range(3))\n",
    "\n",
    "    race_info = {}\n",
    "\n",
    "    for i in range(len(urls)):\n",
    "        race_info.update({race_tracks[i] + ' ' + times[i] : one_race_today(urls[i], delay)})\n",
    "        print('Collected race data for {:s} at {:s}'.format(race_tracks[i], times[i]))\n",
    "\n",
    "    return race_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a069a41d-c391-47a2-8545-71f89144c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def todays_data_df(delay = 1):\n",
    "    races_today = all_races_today(delay)\n",
    "    \n",
    "    simple_list = []\n",
    "    \n",
    "    for race in races_today.keys():\n",
    "        for i in range(len(races_today[race]['Horse'])):\n",
    "            simple_list.append({\n",
    "                'Off Time' : race.split()[1],\n",
    "                'Track' : race.split()[0],\n",
    "                'Horse' : races_today[race]['Horse'][i],\n",
    "                'Runner Num': races_today[race]['Runner Num'][i],\n",
    "                'Tips' : races_today[race]['Tips'][i],\n",
    "                'Last Ran' : races_today[race]['Last Ran'][i],\n",
    "                'Age' : races_today[race]['Ages'][i],\n",
    "            })\n",
    "\n",
    "    return pd.json_normalize(simple_list).set_index('Horse').replace('N/A', np.nan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
